{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dgtBqm-is7kh"
      },
      "outputs": [],
      "source": [
        "# 2  Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, metrics\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Upload the files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "\n",
        "RAW_SW   = \"solar_wind_data.csv\"\n",
        "RAW_GEO  = \"GeomagneticandSolarIndicies.csv\"\n",
        "RAW_HESSI= \"hessi_flare_list.csv\"\n",
        "\n",
        "# 2. Define the cadence\n",
        "CADENCE = \"5T\"  # 5-minute\n",
        "\n",
        "# 3.1 Solar-wind to datetime index\n",
        "sw = pd.read_csv(\"solar_wind_data.csv\")\n",
        "sw[\"Date\"] = pd.to_datetime(sw[\"YYYY\"], format=\"%Y\") + pd.to_timedelta(sw[\"DOY\"] - 1, unit=\"D\")\n",
        "sw[\"DateTime\"] = sw[\"Date\"] + pd.to_timedelta(sw[\"HR\"], unit=\"H\") + pd.to_timedelta(sw[\"MN\"], unit=\"m\")\n",
        "sw = sw.set_index(\"DateTime\").sort_index()\n",
        "sw = sw.drop(columns=[\"YYYY\", \"DOY\", \"HR\", \"MN\", \"Date\"])\n",
        "\n",
        "# 3.2 Resample to 5‑min means (ensures regular grid)\n",
        "sw = sw.resample(CADENCE).mean()\n",
        "\n",
        "# 3.3 Daily geomagnetic / solar indices\n",
        "geo = pd.read_csv(\"GeomagneticandSolarIndicies.csv\")\n",
        "geo[\"Date\"] = pd.to_datetime(geo[[\"Year\", \"Month\", \"Day\"]].astype(str).agg(\"-\".join, axis=1))\n",
        "geo = geo.set_index(\"Date\").sort_index()\n",
        "geo_daily = geo[[\"Daily_Ap\", \"Sunspot_Number\", \"F10.7_Adj\"]]\n",
        "\n",
        "# Forward-fill geomagnetic data to 5‑min cadence\n",
        "geo_5m = geo_daily.reindex(sw.index, method=\"ffill\")\n",
        "\n",
        "# 3.4 Merge datasets\n",
        "df5 = sw.join(geo_5m, how=\"inner\")\n",
        "\n",
        "# 3.5 Create southward vBz proxy\n",
        "df5[\"vBz_south\"] = df5[\"Speed_km_s\"] * df5[\"BZ_GSM_nT\"].clip(upper=0)\n",
        "\n",
        "print(\"5‑min dataframe shape:\", df5.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "eBJi6cubs_He",
        "outputId": "5b77ab56-a344-4a36-e7f5-9740311a4f8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8096a4a4-e5a4-4a2f-b396-3a49fc16f4ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8096a4a4-e5a4-4a2f-b396-3a49fc16f4ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GeomagneticandSolarIndicies.csv to GeomagneticandSolarIndicies.csv\n",
            "Saving hessi_flare_list.csv to hessi_flare_list.csv\n",
            "Saving solar_wind_data.csv to solar_wind_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3f79e1cbe5be>:16: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
            "  sw[\"DateTime\"] = sw[\"Date\"] + pd.to_timedelta(sw[\"HR\"], unit=\"H\") + pd.to_timedelta(sw[\"MN\"], unit=\"m\")\n",
            "<ipython-input-3-3f79e1cbe5be>:21: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  sw = sw.resample(CADENCE).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5‑min dataframe shape: (2630304, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hessi = pd.read_csv(RAW_HESSI)\n",
        "hessi[\"Start_DT\"] = pd.to_datetime(hessi[\"Start_Time\"])\n",
        "flare_series = (hessi.assign(flag=1)\n",
        "                       .set_index(\"Start_DT\")\n",
        "                       .resample(CADENCE)[\"flag\"]\n",
        "                       .max()\n",
        "                       .fillna(0))\n",
        "\n",
        "# Look‑ahead 24 h label\n",
        "# --- FINAL NaN‑removal patch ---------------------------------------------\n",
        "label = (flare_series\n",
        "         .rolling(\"24H\").max()\n",
        "         .shift(-24*60//5)        # look‑ahead 24 h\n",
        "         .reindex(df5.index))\n",
        "\n",
        "# 1️⃣  Replace NaNs with 0 **AND** cast to float32\n",
        "label = label.fillna(0).astype(\"float32\")\n",
        "\n",
        "df5[\"flare_next_24h\"] = label\n",
        "\n",
        "# 2️⃣  Sanity check\n",
        "assert not df5[\"flare_next_24h\"].isna().any(), \"Label still contains NaNs!\"\n",
        "print(\"✅  Label column is NaN‑free\")\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "POS_RATE = df5[\"flare_next_24h\"].mean()\n",
        "print(f\"Positive rate (5‑min grid): {POS_RATE:.4%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MoAAILSwAG4",
        "outputId": "6dfd3f82-d1ad-4b7e-a4f3-866af1cf097c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3e8fbe58e6cb>:5: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
            "  .resample(CADENCE)[\"flag\"]\n",
            "<ipython-input-4-3e8fbe58e6cb>:12: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  .rolling(\"24H\").max()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Label column is NaN‑free\n",
            "Positive rate (5‑min grid): 51.5763%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_end = \"2013-12-31 23:55\"\n",
        "val_end   = \"2016-12-31 23:55\"\n",
        "\n",
        "train_df = df5.loc[:train_end]\n",
        "val_df   = df5.loc[train_end:val_end].iloc[1:]\n",
        "test_df  = df5.loc[val_end:].iloc[1:]\n",
        "\n",
        "print(\"Train rows:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fUQQvDDwIjG",
        "outputId": "5abba4ca-c9a4-453a-aa6e-a2815717446d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 1472832 Val: 315648 Test: 841824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- REPLACEMENT FOR STEP 6 -----------------------------------------------\n",
        "LOOKBACK_STEPS = 576   # 48h @ 5‑min\n",
        "STEP            = 1\n",
        "TARGET_COL      = \"flare_next_24h\"\n",
        "\n",
        "# 1️⃣  Select numeric features\n",
        "feature_cols = [c for c in df5.columns if c not in [TARGET_COL] and\n",
        "                np.issubdtype(df5[c].dtype, np.number)]\n",
        "\n",
        "# 2️⃣  Replace ±Inf with NaN, then fill NaN with 0\n",
        "df5_clean = df5.copy()\n",
        "df5_clean[feature_cols] = df5_clean[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
        "nan_mask = df5_clean[feature_cols].isna().astype(\"float32\")   # 1 = was NaN\n",
        "df5_clean[feature_cols] = df5_clean[feature_cols].fillna(0)\n",
        "\n",
        "# 3️⃣  OPTIONAL: append the missing‑value indicators\n",
        "use_nan_mask = False   # <- set True if you want the model to learn missingness\n",
        "if use_nan_mask:\n",
        "    mask_cols = [f\"{c}_nan\" for c in feature_cols]\n",
        "    df5_clean[mask_cols] = nan_mask\n",
        "    feature_cols = feature_cols + mask_cols\n",
        "\n",
        "print(\"Final feature count:\", len(feature_cols))\n",
        "\n",
        "# 4️⃣  Normalise (mean‑0, std‑1) on TRAIN ONLY\n",
        "mean = df5_clean.loc[:train_end, feature_cols].mean()\n",
        "std  = df5_clean.loc[:train_end, feature_cols].std().replace(0, 1)\n",
        "\n",
        "df5_clean[feature_cols] = (df5_clean[feature_cols] - mean) / std\n",
        "\n",
        "def make_dataset(dataframe, shuffle=False):\n",
        "    x = dataframe[feature_cols].values.astype(\"float32\")\n",
        "    y = dataframe[TARGET_COL].values.astype(\"float32\")\n",
        "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "        x, y,\n",
        "        sequence_length=LOOKBACK_STEPS,\n",
        "        sequence_stride=STEP,\n",
        "        shuffle=shuffle,\n",
        "        batch_size=256\n",
        "    )\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(df5_clean.loc[:train_end], shuffle=True)\n",
        "val_ds   = make_dataset(df5_clean.loc[train_end:val_end].iloc[1:])\n",
        "test_ds  = make_dataset(df5_clean.loc[val_end:].iloc[1:])\n",
        "\n",
        "print(\"Dataset batches – Train:\", len(train_ds),\n",
        "      \"Val:\", len(val_ds),\n",
        "      \"Test:\", len(test_ds))\n",
        "# ---------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkzQoiJkwLV_",
        "outputId": "264a3338-ee16-4794-e104-b8a692e2b450"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature count: 10\n",
            "Dataset batches – Train: 5752 Val: 1231 Test: 3287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pr_auc(y_true, y_pred):\n",
        "    # PR‑AUC via tf‑metrics (works in TF 2.11+)\n",
        "    return tf.keras.metrics.AUC(curve=\"PR\", name=\"pr_auc\")(y_true, y_pred)\n",
        "\n",
        "inputs = layers.Input(shape=(LOOKBACK_STEPS, len(feature_cols)))\n",
        "x = layers.Masking(mask_value=np.nan)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[metrics.AUC(curve=\"ROC\"), metrics.AUC(curve=\"PR\", name=\"pr_auc\")]\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "xjjOzZ-lwOqj",
        "outputId": "3a3ec483-749a-41b0-fa98-f8805ee2296c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m10\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any (\u001b[38;5;33mAny\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m38,400\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m41,216\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,400</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,729\u001b[0m (319.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,729</span> (319.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,729\u001b[0m (319.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,729</span> (319.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU available:\", tf.config.list_physical_devices(\"GPU\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng776_oBwQit",
        "outputId": "7d96ced9-99de-4fde-d14d-3896348c3006"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early = callbacks.EarlyStopping(monitor=\"val_pr_auc\",\n",
        "                                mode=\"max\",\n",
        "                                patience=5,\n",
        "                                restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=30,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo_kjd90wSMO",
        "outputId": "4c3dd442-d7d1-4124-ed78-304927943d09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 140ms/step - auc: 0.8411 - loss: 0.4401 - pr_auc: 0.9223 - val_auc: 0.4712 - val_loss: 0.7651 - val_pr_auc: 0.8091\n",
            "Epoch 2/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 139ms/step - auc: 0.8815 - loss: 0.3859 - pr_auc: 0.9456 - val_auc: 0.5672 - val_loss: 0.9408 - val_pr_auc: 0.8523\n",
            "Epoch 3/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 140ms/step - auc: 0.9420 - loss: 0.2703 - pr_auc: 0.9738 - val_auc: 0.5956 - val_loss: 1.3600 - val_pr_auc: 0.8585\n",
            "Epoch 4/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m866s\u001b[0m 141ms/step - auc: 0.9719 - loss: 0.1921 - pr_auc: 0.9873 - val_auc: 0.5559 - val_loss: 1.9563 - val_pr_auc: 0.8404\n",
            "Epoch 5/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 140ms/step - auc: 0.9891 - loss: 0.1209 - pr_auc: 0.9950 - val_auc: 0.5243 - val_loss: 2.4432 - val_pr_auc: 0.8293\n",
            "Epoch 6/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 140ms/step - auc: 0.9951 - loss: 0.0784 - pr_auc: 0.9976 - val_auc: 0.5219 - val_loss: 2.5930 - val_pr_auc: 0.8270\n",
            "Epoch 7/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 140ms/step - auc: 0.9978 - loss: 0.0487 - pr_auc: 0.9988 - val_auc: 0.5184 - val_loss: 2.8751 - val_pr_auc: 0.8247\n",
            "Epoch 8/30\n",
            "\u001b[1m5752/5752\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 140ms/step - auc: 0.9986 - loss: 0.0357 - pr_auc: 0.9992 - val_auc: 0.5245 - val_loss: 2.9117 - val_pr_auc: 0.8264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# 1. Create a directory to hold both formats\n",
        "MODEL_DIR = \"saved_models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# 2. Save in modern .keras format (recommended)\n",
        "keras_path = f\"{MODEL_DIR}/lstm_model_thisone.keras\"\n",
        "model.save(keras_path)\n",
        "\n",
        "# 3. Save in legacy .h5 format (less reliable, but portable if needed)\n",
        "h5_path = f\"{MODEL_DIR}/lstm_model_thisone.h5\"\n",
        "model.save(h5_path, save_format=\"h5\")  # explicitly set format to h5\n",
        "\n",
        "# 4. Download both files\n",
        "files.download(keras_path)\n",
        "files.download(h5_path)"
      ],
      "metadata": {
        "id": "tB6uWYsfv6yu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f2a06dce-47b3-4661-ecc6-6e07234e236c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8fe5ffc6-7294-4ede-bb64-81ca6d71bbf4\", \"lstm_model_thisone.keras\", 1045574)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3e37cd7-000b-4125-ada2-832e1cf4196e\", \"lstm_model_thisone.h5\", 1044624)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(test_ds).ravel()\n",
        "test_true = np.concatenate([y for _, y in test_ds])\n",
        "\n",
        "roc = roc_auc_score(test_true, test_pred)\n",
        "pr  = average_precision_score(test_true, test_pred)\n",
        "print(f\"TEST  – ROC‑AUC: {roc:.3f}  PR‑AUC: {pr:.3f}\")"
      ],
      "metadata": {
        "id": "LR3A577uiMr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164a552c-560b-49a9-96d7-0fb4c2e83f31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3287/3287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 58ms/step\n",
            "TEST  – ROC‑AUC: 0.581  PR‑AUC: 0.101\n"
          ]
        }
      ]
    }
  ]
}